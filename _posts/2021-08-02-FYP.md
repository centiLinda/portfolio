---
title: Final Year Project - Development of A Robotic Guide Dog
layout: post
---
<div style="text-align: left"><u>Aug 2021 - Present</u></div>
The objective is to develop `a robotic guide dog` that has similar performance as a real guide dog. Consider that the cost for raising a real guide dog is high and the current availability for visually impaired people is not ideal, such robot will greatly improve the mobility of those in need.

---
{: data-content="Plan"}

Stages of development:
1. <b>[done]</b> Basic movement: turn left/right, straight-on, stop
2. Guide to specific spot: find lift, find gate
3. Speed control with force feedback
4. Test in public areas and with real guide dog users

---
{: data-content="Resources"}

Hardware List:
- Unitree A1 robot dog
    - Raspberry Pi: WiFi access point, ROS master, camera vision
    - UP board: Low level joint control
    - Intel RealSense camera: RGB and Depth
    - Slamtec Slamware & RPLiDAR 2D: mapping and navigation
- Jetson Nano: Ubuntu environment for ROS development and software testing

Software List:
- ROS Kinetic: robotics system to connect every function
- PocketSphinx: light weight voice recognition engine
- Slamware ROS SDK: mapping and navigation tool
- YOLOv3 and OpenCV: object detection tool

---
{: data-content="Demos"}

<p align="center"><video height="700" controls>
  <source type="video/mp4" src="http://centiLinda.github.io/portfolio/assets/images/fyp_1.mp4">
</video></p>
<div style="text-align: center"><em>Listening to real-time voice command</em></div>